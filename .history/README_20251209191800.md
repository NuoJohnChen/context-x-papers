# Community-Federated Conference (CFC) Curation Engine & XtraMCP Researcher Node

**English | [中文在下方](#社区联邦会议-cfc-策展引擎--xtramcp-researcher-节点)**

This repository houses the core intelligence for semantic literature retrieval and topic discovery. It serves as the backend engine for the Researcher Module within the **XtraMCP** framework [1], powering the **PaperDebugger** writing assistant [3]. Furthermore, it provides the technological infrastructure required to operationalize the **Community-Federated Conference (CFC)** model, addressing the sustainability crisis in centralized AI conferences [2].

---

## 1. Data Ingestion: The `paperdb` Pipeline

The foundation of this system lies in the `paperdb/` directory, which constructs the comprehensive knowledge base required for semantic analysis.

### Function

This module scrapes and aggregates arXiv metadata and utilizes **Specter2** to generate document-level vector embeddings.

### Outputs

It produces two critical artifacts:

- `arxiv_merged.parquet`: A structured dataset containing metadata (titles, abstracts, authors, categories) for ~700,000 papers.
- `embeddings.npy`: A dense vector file containing the pre-computed embeddings.

### Integration

These files are loaded directly by `app.py` to initialize the `WorkshopRecommender` class, enabling low-latency retrieval **without** the need for real-time inference on the entire corpus.

---

## 2. Core Functionalities: Context2Papers & Papers2Context

The `app.py` engine utilizes the data from `paperdb` to implement two bidirectional flows of information:

- **Context2Papers**: Semantic Retrieval & Recommendation
- **Papers2Context**: Topic Discovery & Trend Analysis

### 2.1 Context2Papers: Semantic Retrieval & Recommendation

**Goal:** Retrieve high-precision, relevant academic papers given a specific research context (e.g., a workshop description, abstract, or research query).

#### Implementation

1. **Vectorization (Recall)**

   - Use **Specter2** (`allenai/specter2_base`) to convert user queries into vectors compatible with the pre-computed `embeddings.npy`.
   - Perform dense retrieval via **cosine similarity** to recall the top‑k candidate papers.
2. **Re-ranking (Precision)**

   - To correct for information loss in vector compression, employ a **Large Language Model Re-ranker** (`Qwen/Qwen3-Reranker-8B`).
   - This component re-scores candidates by analyzing the full contextual alignment between the query and each paper, ensuring superior relevance.

### 2.2 Papers2Context: Topic Discovery & Trend Analysis

**Goal:** Automatically discover latent themes, research trends, and “contexts” from the massive collection of papers in `arxiv_merged.parquet`, optionally filtered by region or time.

#### Implementation

1. **Clustering Pipeline**

   - Implement **BERTopic** to perform dynamic topic modeling.
2. **Dimensionality Reduction**

   - Use **UMAP** to reduce the high-dimensional Specter2 embeddings into a space amenable to clustering.
3. **Density Clustering**

   - Apply **HDBSCAN** to identify dense clusters of papers representing emerging research fronts.
4. **Topic Representation**

   - Use `CountVectorizer` to extract class-based TF-IDF keywords and generate human-readable labels for each identified context.

---

## 3. Role in XtraMCP & PaperDebugger

This repository functions as the **Researcher Node** within the XtraMCP architecture, decoupling orchestration from reasoning [1].

### 3.1 The Researcher of XtraMCP

- Acts as the **execution layer** for the Researcher Module.
  - When the XtraMCP control layer receives a user intent (e.g., “Find related work”), it routes the request to this backend via the **Model Context Protocol (MCP)**.
- Provides a **Hallucination-Free Safeguard**:
  - Unlike standard LLMs that may fabricate citations, this module performs **deterministic retrieval** over the vector database created by `paperdb`, ensuring every recommendation is empirically verifiable.

### 3.2 Service to PaperDebugger

**PaperDebugger** [3], the user-facing Overleaf extension, relies on this backend to provide real-time **“Deep Research”** capabilities.

- By analyzing the user’s current manuscript draft, this engine:
  - Retrieves relevant literature; and
  - Generates **Relevance Insights**, helping authors position their work against the state of the art.

---

## 4. Addressing the AI Conference Crisis (CFC Model)

The current centralized AI conference model is unsustainable due to exponential submission growth and inefficient knowledge dissemination [2]. This codebase serves as the technical foundation for the proposed **Community-Federated Conference (CFC)** solution.

### 4.1 Solving Information Overload

By utilizing **Context2Papers**, we enable the **“Scientific Mission”** of efficient knowledge exchange:

- Researchers can cut through the noise of thousands of submissions to find work specifically relevant to their **context**.

### 4.2 Enabling Federated Regional Hubs

The CFC model proposes separating peer review from presentation via **Federated Regional Hubs** (local gatherings of 500–1500 participants).

- **Papers2Context** is critical for organizers of these hubs:
  - By filtering `arxiv_merged.parquet` by region (e.g., “Singapore”) and running topic discovery, organizers can identify dominant local research themes.
  - This enables curation of targeted, high-value workshops.

This restores the **“Community Building”** pillar by fostering meaningful, localized interactions rather than anonymous mega‑conferences.

---

## References

[1] XtraMCP: A Context-Aware Assistant for Enhancing Academic Writing and Revision.
[2] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conferences.
[3] PaperDebugger: AI-powered academic writing assistant for LaTeX & Overleaf.

---

## 社区联邦会议 (CFC) 策展引擎 & XtraMCP Researcher 节点

本仓库承载了用于**语义文献检索**与**主题发现**的核心智能模块。
它作为 **XtraMCP 框架** [1] 中 Researcher 模块的后端引擎，为写作助手 **PaperDebugger** [3] 提供能力支持。
同时，它也是实现 **社区联邦会议（Community-Federated Conference, CFC）** 模型的技术底座，用于应对当前集中式 AI 顶会体系面临的可持续性危机 [2]。

---

## 1. 数据摄取：`paperdb` 流水线

系统的基础由 `paperdb/` 目录构成，它负责构建语义分析所需的综合知识库。

### 功能

该模块抓取并聚合 arXiv 元数据，并使用 **Specter2** 生成文档级别的向量嵌入。

### 输出

生成两个关键产物：

- `arxiv_merged.parquet`：包含约 70 万篇论文的结构化元数据（标题、摘要、作者、类别等）。
- `embeddings.npy`：
  存储对应论文的预计算稠密向量表示。

### 集成方式

上述文件由 `app.py` 直接加载，用于初始化 `WorkshopRecommender` 类，实现**低延迟检索**，无需对全量语料进行实时推理。

---

## 2. 核心功能：Context2Papers 与 Papers2Context

`app.py` 基于 `paperdb` 数据，实现了两个方向的信息流：

- **Context2Papers**：语义检索与推荐
- **Papers2Context**：主题发现与趋势分析

### 2.1 Context2Papers：语义检索与文献推荐

**目标：**
在给定具体研究语境（如：workshop 描述、论文摘要、研究查询）的情况下，检索出高精度且高度相关的学术论文。

#### 实现流程

1. **向量化（召回层）**

   - 使用 **Specter2**（`allenai/specter2_base`）将用户查询转换为向量，与预计算的 `embeddings.npy` 保持同一语义空间。
   - 通过 **余弦相似度** 进行稠密向量检索，召回 top‑k 候选论文。
2. **重排序（精排层）**

   - 针对向量压缩带来的信息损失，引入 **大模型重排序器**（`Qwen/Qwen3-Reranker-8B`）。
   - 对召回候选进行再次打分，综合分析查询与论文全文语境之间的匹配程度，从而显著提升结果相关性。

### 2.2 Papers2Context：主题发现与趋势分析

**目标：**
在大规模论文集合 `arxiv_merged.parquet` 上（可按地区或时间过滤），自动发现潜在主题、研究趋势及“上下文语境”。

#### 实现流程

1. **聚类管线**

   - 使用 **BERTopic** 实现动态主题建模。
2. **降维**

   - 使用 **UMAP** 将高维 Specter2 嵌入降至可聚类的低维空间。
3. **密度聚类**

   - 使用 **HDBSCAN** 识别论文在嵌入空间中的高密度簇，对应新兴研究前沿或局部热点方向。
4. **主题表示**

   - 通过 `CountVectorizer` 提取基于类别的 TF-IDF 关键词，为每个识别出的“语境/主题”生成可读的标签与描述。

---

## 3. 在 XtraMCP & PaperDebugger 中的角色

本仓库是 XtraMCP 架构中的 **Researcher 节点**，实现了**编排层与推理层的解耦** [1]。

### 3.1 作为 XtraMCP 的 Researcher

- 充当 Researcher 模块的**执行层**：
  - 当 XtraMCP 控制层接收到用户意图（例如：“帮我找相关工作”）后，会通过 **Model Context Protocol (MCP)** 将请求路由至本后端。
- 提供 **“零幻觉”安全保障**：
  - 与常规 LLM 可能“编造引用”不同，本模块基于 `paperdb` 构建的向量数据库进行**确定性检索**，保证每一条推荐都可在真实文献中被验证追溯。

### 3.2 对 PaperDebugger 的支撑

面向用户的 Overleaf 扩展 **PaperDebugger** [3] 使用本后端提供的实时 **“深度检索（Deep Research）”** 能力：

- 基于用户当前稿件内容进行分析：
  - 检索与稿件高度相关的文献；
  - 生成**相关性洞察（Relevance Insights）**，辅助作者理解自身工作在现有研究版图中的位置与贡献。

---

## 4. 应对 AI 会议危机：CFC 模型

当前集中化 AI 顶会模式面临**投稿量指数级膨胀**与**知识传播低效**等问题，难以为继 [2]。
本代码库是解决方案 **社区联邦会议（CFC）模型** 的技术基础。

### 4.1 缓解信息过载

通过 **Context2Papers**，系统实现了“**科学使命（Scientific Mission）**”中高效知识交流的目标：

- 研究者可以从成千上万篇投稿和预印本中，快速筛选出与自身**具体语境**高度相关的工作。

### 4.2 支撑联邦式区域 Hub

CFC 模型提出：将“评审”与“展示”解耦，通过规模约为 500–1500 人的 **区域 Hub（Federated Regional Hubs）** 组织线下交流。

- **Papers2Context** 对这些 Hub 的组织者至关重要：
  - 可按地区（如：“Singapore”）过滤 `arxiv_merged.parquet`；
  - 运行主题发现后，识别该地区的主导研究主题与新兴方向；
  - 据此策划高度聚焦、价值密度高的 workshop 与专题讨论。

这有助于重建学术会议的“**社区建设（Community Building）**”支柱，促成基于真实社群与地缘关系的深度互动，而非匿名、超大规模的聚合式会议。

---

## 参考文献

[1] XtraMCP: A Context-Aware Assistant for Enhancing Academic Writing and Revision.
[2] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conferences.
[3] PaperDebugger: AI-powered academic writing assistant for LaTeX & Overleaf.
