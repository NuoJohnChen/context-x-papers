# XtraMCP Researcher Node & Community-Federated Conference (CFC) Curation Engine

> 点击切换语言 · Click to switch language：
> **[English](./README.md)** | **[中文](./README_zh.md)**

### 1. Overview

This repository houses the core intelligence for **semantic literature retrieval** and **topic discovery**. It serves as the backend engine for the Researcher Module within the **XtraMCP** framework [1 , 2 XtraGPT], powering the **PaperDebugger** writing assistant [1, ]. It also provides the technological infrastructure required to operationalize the **Community-Federated Conference (CFC)** model, which addresses the sustainability crisis in centralized AI conferences [3].

---

### 2. Data Ingestion: The `paperdb` Pipeline

The foundation of this system lies in the `paperdb/` directory, which constructs the comprehensive knowledge base required for semantic analysis.

#### 2.1 Function

This module scrapes and aggregates arXiv metadata and uses **Specter2** to generate document-level vector embeddings.

#### 2.2 Outputs

It produces two critical artifacts:

- `arxiv_merged.parquet`A structured dataset containing metadata (titles, abstracts, authors, categories) for ~700,000 papers.
- `embeddings.npy`
  A dense vector file containing the pre-computed embeddings corresponding to the papers.

#### 2.3 Integration

These files are loaded directly by `app.py` to initialize the `WorkshopRecommender` class, enabling low-latency retrieval **without** real-time inference over the entire corpus.

---

### 3. Core Functionalities: Context2Papers & Papers2Context

The `app.py` engine utilizes `paperdb` data to implement two bidirectional flows of information:

- **Context2Papers** – Semantic Retrieval & Recommendation
- **Papers2Context** – Topic Discovery & Trend Analysis

---

#### 3.1 Context2Papers: Semantic Retrieval & Recommendation

**Goal:** Retrieve high-precision, relevant academic papers given a specific research context (e.g., workshop description, abstract, or research query).

##### Implementation

1. **Vectorization (Recall Layer)**

   - Use **Specter2** (`allenai/specter2_base`) to convert user queries into vectors compatible with the pre-computed `embeddings.npy`.
   - Perform dense retrieval via **cosine similarity** to recall the top‑k candidate papers.
2. **Re-ranking (Precision Layer)**

   - To compensate for information loss from vector compression, employ a **Large Language Model Re-ranker** (`Qwen/Qwen3-Reranker-8B`).
   - It re-scores candidates by assessing full contextual alignment between the query and each paper, substantially improving relevance.

---

#### 3.2 Papers2Context: Topic Discovery & Trend Analysis

**Goal:** Automatically discover latent themes, research trends, and “contexts” from the large collection of papers in `arxiv_merged.parquet`, optionally filtered by region or time.

##### Implementation

1. **Clustering Pipeline**

   - Use **BERTopic** for dynamic topic modeling.
2. **Dimensionality Reduction**

   - Apply **UMAP** to reduce high-dimensional Specter2 embeddings into a clusterable low-dimensional space.
3. **Density Clustering**

   - Use **HDBSCAN** to identify dense clusters of papers, corresponding to emerging research fronts or local hotspots.
4. **Topic Representation**

   - Use `CountVectorizer` to extract class-based TF-IDF keywords and produce human-readable labels for each discovered context/topic.

---

### 4. Role in XtraMCP & PaperDebugger

This repository functions as the **Researcher Node** within the XtraMCP architecture, decoupling orchestration from reasoning [1].

#### 4.1 Researcher in the XtraMCP Architecture

- Acts as the **execution layer** for the Researcher Module.
  - When the XtraMCP control layer receives a user intent (e.g., “Find related work”), it routes the request to this backend via the **Model Context Protocol (MCP)**.
- Provides a **hallucination-free safeguard**:
  - Instead of fabricating citations (a common failure mode of generic LLMs), this module performs **deterministic retrieval** over the vector database created by `paperdb`, ensuring that every recommendation is grounded in real, verifiable literature.

#### 4.2 Service to PaperDebugger

The user-facing Overleaf extension **PaperDebugger** [3] uses this backend to provide real-time **Deep Research** capabilities:

- It analyzes the user’s current manuscript draft to:
  - retrieve highly relevant literature; and
  - generate **Relevance Insights** that help authors position their work within, and against, the state of the art.

---

### 5. Addressing the AI Conference Crisis: The CFC Model

Centralized AI conference models are becoming unsustainable due to **exponential growth in submissions** and **inefficient knowledge dissemination** [2]. This codebase is the technical backbone of the proposed **Community-Federated Conference (CFC)** solution.

#### 5.1 Mitigating Information Overload

Using **Context2Papers**, the system supports the **Scientific Mission** of efficient knowledge exchange:

- Researchers can cut through thousands of submissions and preprints to quickly find work that is highly relevant to their **specific context**.

#### 5.2 Enabling Federated Regional Hubs

The CFC model decouples **peer review** from **presentation**, organizing in-person interaction through **Federated Regional Hubs** (local gatherings of roughly 500–1500 participants).

- **Papers2Context** is crucial for hub organizers:
  - Filter `arxiv_merged.parquet` by region (e.g., “Singapore”).
  - Run topic discovery to identify dominant local research themes and emerging directions.
  - Curate highly focused, high-value workshops and symposia based on these insights.

This helps restore the **Community Building** function of conferences, enabling deep, locality-aware interactions instead of anonymous, oversized mega-events.

---

### 6. References

[1] XtraMCP: A Context-Aware Assistant for Enhancing Academic Writing and Revision.
[2] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conferences.
[3] PaperDebugger: AI-powered academic writing assistant for LaTeX & Overleaf.

### 1. 概览

本仓库承载了用于 **语义文献检索** 与 **主题发现** 的核心智能模块。
它作为 **XtraMCP 框架** [1] 中 Researcher 模块的后端引擎，为写作助手 **PaperDebugger** [3] 提供能力支持。
同时，本仓库也是实现 **社区联邦会议（Community-Federated Conference, CFC）** 模型的技术底座，用于应对当前集中式 AI 顶会体系的可持续性危机 [2]。

---

### 2. 数据摄取：`paperdb` 流水线

系统的基础由 `paperdb/` 目录构成，用于构建语义分析所需的综合知识库。

#### 2.1 功能

该模块抓取并聚合 arXiv 元数据，并使用 **Specter2** 生成文档级别的向量嵌入。

#### 2.2 输出

生成两个关键产物：

- `arxiv_merged.parquet`约 70 万篇论文的结构化元数据集，包含标题、摘要、作者、类别等信息。
- `embeddings.npy`
  与上述论文一一对应的预计算稠密向量文件。

#### 2.3 集成方式

`app.py` 会直接加载这两个文件，用于初始化 `WorkshopRecommender` 类，从而实现**低延迟检索**，无需对全量语料进行实时向量化推理。

---

### 3. 核心功能：Context2Papers 与 Papers2Context

`app.py` 基于 `paperdb` 数据，实现了两个方向的信息流：

- **Context2Papers**：语义检索与文献推荐
- **Papers2Context**：主题发现与趋势分析

---

#### 3.1 Context2Papers：语义检索与文献推荐

**目标：**
在给定具体研究语境（如 workshop 描述、论文摘要、研究问题）的前提下，检索出高精度且高度相关的学术论文。

##### 实现流程

1. **向量化（召回层）**

   - 使用 **Specter2**（`allenai/specter2_base`）将用户查询转换为向量，并与预计算的 `embeddings.npy` 处于同一语义空间。
   - 通过 **余弦相似度** 进行稠密向量检索，召回 top‑k 候选论文。
2. **重排序（精排层）**

   - 针对向量压缩带来的信息损失，引入 **大模型重排序器**（`Qwen/Qwen3-Reranker-8B`）。
   - 对召回候选进行再次打分，综合分析查询与论文在语义和上下文层面的匹配程度，从而显著提升结果相关性。

---

#### 3.2 Papers2Context：主题发现与趋势分析

**目标：**
在 `arxiv_merged.parquet` 大规模论文集合上（可按地区、时间等过滤），自动发现潜在主题、研究趋势与“语境”。

##### 实现流程

1. **聚类管线**

   - 使用 **BERTopic** 完成动态主题建模。
2. **降维**

   - 采用 **UMAP** 将高维 Specter2 嵌入降至适合聚类的低维空间。
3. **密度聚类**

   - 使用 **HDBSCAN** 识别嵌入空间中的高密度簇，这些簇往往对应新兴研究前沿或局部热点。
4. **主题表示**

   - 通过 `CountVectorizer` 提取基于类别的 TF-IDF 关键词，为每个识别出来的“语境 / 主题”生成可读化标签与描述。

---

### 4. 在 XtraMCP 与 PaperDebugger 中的角色

本仓库是 XtraMCP 架构中的 **Researcher 节点**，实现了**编排层与推理层的解耦** [1]。

#### 4.1 作为 XtraMCP 的 Researcher

- 承担 Researcher 模块的**执行层**职责：
  - 当 XtraMCP 控制层接收到用户意图（如“帮我找相关工作”）后，会通过 **Model Context Protocol (MCP)** 将请求路由至本后端。
- 提供 **“零幻觉”安全保障**：
  - 与常规大模型可能“编造引用”不同，本模块基于 `paperdb` 构建的向量数据库进行**确定性检索**，保证每一条推荐都可在真实文献中被验证和追溯。

#### 4.2 对 PaperDebugger 的支撑

面向用户的 Overleaf 扩展 **PaperDebugger** [3] 使用本后端提供的实时 **“深度检索（Deep Research）”** 能力：

- 基于用户当前稿件内容进行语义分析：
  - 检索与稿件高度相关的文献；
  - 生成**相关性洞察（Relevance Insights）**，帮助作者理解自身工作的创新点和其在现有研究版图中的位置。

---

### 5. 应对 AI 会议危机：CFC 模型

集中式 AI 顶会模式正因**投稿量指数级膨胀**与**知识传播低效**而变得难以为继 [2]。
本代码库是解决这一问题的 **社区联邦会议（CFC）模型** 的技术基础。

#### 5.1 缓解信息过载

通过 **Context2Papers**，系统支撑了学术会议的“**科学使命（Scientific Mission）**”——高效的知识交换：

- 研究者可以从海量投稿与预印本中，快速筛选出与自己**具体研究语境**高度相关的工作，降低信息噪声。

#### 5.2 支撑联邦式区域 Hub

CFC 模型将“评审”与“展示”解耦，通过规模约为 500–1500 人的 **区域 Hub（Federated Regional Hubs）** 来组织线下交流。

- **Papers2Context** 对这些 Hub 的组织者尤为关键：
  - 可按地区（如 “Singapore”）过滤 `arxiv_merged.parquet`；
  - 运行主题发现，识别该地区的主导研究方向与新兴趋势；
  - 进而策划高度聚焦、价值密度高的 workshop 与专题讨论。

这有助于重建会议的“**社区建设（Community Building）**”功能，让学术交流回到基于真实社群和地缘关系的深度互动，而非匿名、超大规模的聚合式会议。

---

### 6. 参考文献

[1] XtraMCP: A Context-Aware Assistant for Enhancing Academic Writing and Revision.
[2] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conferences.
[3] PaperDebugger: AI-powered academic writing assistant for LaTeX & Overleaf.
